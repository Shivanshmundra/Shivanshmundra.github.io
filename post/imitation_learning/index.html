<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Shivansh Mundra">

  
  
  
    
  
  <meta name="description" content="Jude is an amateur football player but a wannabe great player. Jude is a die-hard fan of Christiano Ronaldo and watches every time he is playing anywhere.
Jude wondered if he could exactly be like Ronaldo.">

  
  <link rel="alternate" hreflang="en-us" href="https://shivanshmundra.github.io/post/imitation_learning/">

  


  
  
  
  <meta name="theme-color" content="#3f51b5">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://shivanshmundra.github.io/post/imitation_learning/">

  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@MundraShivansh">
  <meta property="twitter:creator" content="@MundraShivansh">
  
  <meta property="og:site_name" content="Shivansh Mundra">
  <meta property="og:url" content="https://shivanshmundra.github.io/post/imitation_learning/">
  <meta property="og:title" content="Intro to Imitation Learning: From Why to How! | Shivansh Mundra">
  <meta property="og:description" content="Jude is an amateur football player but a wannabe great player. Jude is a die-hard fan of Christiano Ronaldo and watches every time he is playing anywhere.
Jude wondered if he could exactly be like Ronaldo."><meta property="og:image" content="https://shivanshmundra.github.io/post/imitation_learning/featured.jpeg">
  <meta property="twitter:image" content="https://shivanshmundra.github.io/post/imitation_learning/featured.jpeg"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-04-19T02:15:34&#43;05:30">
    
    <meta property="article:modified_time" content="2020-04-19T02:15:34&#43;05:30">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://shivanshmundra.github.io/post/imitation_learning/"
  },
  "headline": "Intro to Imitation Learning: From Why to How!",
  
  "image": [
    "https://shivanshmundra.github.io/post/imitation_learning/featured.jpeg"
  ],
  
  "datePublished": "2020-04-19T02:15:34+05:30",
  "dateModified": "2020-04-19T02:15:34+05:30",
  
  "author": {
    "@type": "Person",
    "name": "Shivansh Mundra"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Shivansh Mundra",
    "logo": {
      "@type": "ImageObject",
      "url": "https://shivanshmundra.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "Jude is an amateur football player but a wannabe great player. Jude is a die-hard fan of Christiano Ronaldo and watches every time he is playing anywhere.\nJude wondered if he could exactly be like Ronaldo."
}
</script>

  

  


  


  





  <title>Intro to Imitation Learning: From Why to How! | Shivansh Mundra</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Shivansh Mundra</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Shivansh Mundra</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/post/"><span>Blogs</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/paper_summary/"><span>Paper Summary</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#featured"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link js-theme-selector" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-palette" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      

    </ul>

  </div>
</nav>


  <article class="article">

  




















  
  


<div class="article-container pt-3">
  <h1>Intro to Imitation Learning: From Why to How!</h1>

  
  <p class="page-subtitle">What is Imitation learning, Why do we need it and How to implement different algorithms of IL?</p>
  

  


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/admin/">Shivansh Mundra</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Apr 19, 2020
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    7 min read
  </span>
  

  
  
  
  <span class="middot-divider"></span>
  <a href="/post/imitation_learning/#disqus_thread"></a>
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/categories/technical/">Technical</a>, <a href="/categories/artificial-intelligence/">Artificial Intelligence</a></span>
  

</div>

  














</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 275px; max-height: 183px;">
  <div style="position: relative">
    <img src="/post/imitation_learning/featured.jpeg" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      <p>Jude is an amateur football player but a wannabe great player. Jude is a die-hard fan of Christiano Ronaldo and watches every time he is playing anywhere.</p>
<p>Jude wondered if he could exactly be like Ronaldo. If by humongous practice, he could imitate all skills Ronaldo has. He doesn&rsquo;t care that while imitating if he is scoring a goal or not, he would just kick as Ronaldo would have kicked.</p>
<blockquote>
<p>If I would kick exactly like Ronaldo, it would definitely be a goal!</p>
</blockquote>
<p>Jude was fascinated by this idea, but also he was <strong>too lazy</strong> and <strong>loved programming</strong>(eternal bond). He thought why couldn’t he do something very similar in the virtual world, after all, he could fast forward this training process as he controls this virtual world.</p>
<p><img src="/img/football.jpeg" alt="Football image"></p>
<p>Jude stumbled upon exactly what he was looking for</p>
<h3 id="imitation-learning">Imitation Learning</h3>
<p>Continuing Jude&rsquo;s story, as he watches Ronaldo a lot, he knows what he would do in numerous situations thrown at him. Let’s say Jude has practised and can mimic exactly Ronaldo in those <strong>exactly the same situations</strong>.</p>
<p>As the number of situations Ronaldo(or any football player) can be in is infinite, Jude can’t learn on all of them, how hard he tries! And since Jude was so busy in replicating Ronaldo, he didn’t learn anything when an unknown situation arises.</p>
<p>Also, since Jude is human just like us, there is nothing like <strong>exactly like</strong> Ronaldo. However hard he try, there would be some scope of mistake every time!</p>
<p>We would see above circumstances projected mathematically later.</p>
<blockquote>
<p>We can be wrong, or we can know it, but we can’t do both at the same time</p>
</blockquote>
<p>If you understood Jude, you got Imitation learning. 😄</p>
<h3 id="different-learning-paradigms">Different Learning Paradigms</h3>
<p>Let us quickly define three verticals of machine learning which would help define our problem statement.</p>
<ul>
<li>Supervised learning: Basically Find x<sub>s</sub> and y<sub>s</sub>, define a model and fit model to predict y<sub>s</sub>.</li>
<li>Unsupervised learning: We wish to inherently learn the structure of data without <strong>explicitly</strong> using labels.</li>
<li>Reinforcement learning: It&rsquo;s about taking suitable actions in order to maximize reward in an environment.</li>
</ul>
<h3 id="now-why-imitation-learning">Now Why Imitation Learning?</h3>
<p>Now consider that Jude won&rsquo;t use Imitation learning as of now and want to train himself for every situation with objective being shooting a goal using Reinforcement learning.</p>
<p>In RL setting, reward for shooting a goal would be <strong>+1</strong> and for rest it would be <strong>0</strong>. As you know, this kind of reward is very sparse in nature. There may be handful of time where agent(Jude in our case!) would receive a positive reward to learn from.</p>
<blockquote>
<p>The reward sparsity is one of the issues that hinders us in beating Montezuma’s Revenge — a notoriously hard Atari 2600 game, that has not been cracked yet.</p>
</blockquote>
<p>Another issue is one we discussed above, we need virtual simulators to fasten this process of learning but what if we don&rsquo;t have one or we want to learn something in real life?</p>
<p>Imitation learning can potentially solve these problems and also a bunch of others.</p>





  











<figure id="figure-virtual-humanoid-trying-to-imitate-human-in-running">


  <a data-fancybox="" href="/img/humanoid_imitation.gif" data-caption="Virtual Humanoid trying to imitate Human in running">


  <img src="/img/humanoid_imitation.gif" alt=""  >
</a>


  
  
  <figcaption>
    Virtual Humanoid trying to imitate Human in running
  </figcaption>


</figure>

<h3 id="how-imitation-learning">How Imitation learning?</h3>
<p>Generally, Imitation learning is useful when it is easier for an expert to demonstrate the desired behaviour so that we don&rsquo;t have to specify any reward function.</p>
<p>Let&rsquo;s say we collect expert demonstrations (also known as trajectories in RL setting)</p>
<p>$\tau$ = (s<sub>0</sub>, a<sub>0</sub>, s<sub>1</sub>, a<sub>1</sub>&hellip;..) where actions (A<sub>s</sub>) are based on expert&rsquo;s policy(say human brain).  In some cases, we may require presence of &ldquo;<strong>expert</strong>&rdquo; during training.</p>
<p>Once we get this trajectory, we slice this on each time step to get pairs of S<sub>s</sub> and A<sub>s</sub>.</p>
<p>We then treat these pairs as i.i.d examples and apply <strong>Supervised learning</strong>.</p>
<p>Changing loss function and optimisation strategies in this learning define various imitation learning algorithms. Let&rsquo;s look at basic ones in them.</p>
<h3 id="behaviour-cloning">Behaviour Cloning</h3>
<p>This is simplest form of imitation learning where you treat these pairs(S<sub>s</sub>, A<sub>s</sub>) as i.i.d examples and apply simple supervised learning. We can choose the model to a tree based (Random Forest, Gradient Boosting) or Neural Networks depending on complexity of state and action space.</p>
<h6 id="enough-of-talks-lets-see-implementation">Enough of talks, let&rsquo;s see implementation!</h6>
<p>You can head over to this folder : <a href="https://github.com/Shivanshmundra/reinforcement_learning_beginner/tree/master/imitation_learning_bc">https://github.com/Shivanshmundra/reinforcement_learning_beginner/tree/master/imitation_learning_bc</a></p>
<p>Here, you can run <code>expert_recorder.py</code> to record expert demonstrations, expert being you!. Right now it uses <code>MountainCar-v0</code> environment where you have only 2 actions - right or left, to climb a mountain. You can guide by using <code>a</code> and <code>d</code> for right and left respectively. You can change environment according to your ease too!</p>
<p>Once you have created &ldquo;expert demonstrations&rdquo;,  you can build a model and train on collected data. Trained policy then can be used to test on same environment.</p>
<p>Extensive instructions are in <code>README</code> of folder. Also, I have borrowed this code, so to get good understanding of code, you can watch 
<a href="https://www.youtube.com/watch?v=0rsrDOXsSeM&amp;feature=youtu.be&amp;t=1370" target="_blank" rel="noopener">this</a> video.</p>
<p>Once trained, it looks something like this:</p>





  











<figure id="figure-mountain-car-trained-using-behaviour-cloning">


  <a data-fancybox="" href="/img/imitation_learning.gif" data-caption="Mountain Car trained using Behaviour Cloning">


  <img src="/img/imitation_learning.gif" alt=""  >
</a>


  
  
  <figcaption>
    Mountain Car trained using Behaviour Cloning
  </figcaption>


</figure>

<h5 id="shortcomings">Shortcomings</h5>
<p>In some cases, Behavioural cloning can work excellently, precisely where there are limited number of states and time frame of an episode is very short.</p>
<p>Main reason for Behaviour cloning to not work generally is the i.i.d assumption we took above for supervised learning, while in real scenario like an MDP(Markov Decision Process) an action induces the next state, which breaks i.i.d assumption.</p>
<p>Also, as you know this algorithms is only trained on given states as we previously talked that no machine learning algorithm is 100% accurate, there is a chance of error on some time step $t$ and this error will keep on increasing with $t$ as with every wrong decision, agent might fall into an &ldquo;more unknown&rdquo; state thus prone to make more error.</p>
<p>In above cases, BC behaviour is undefined and can lead to catastrophic failures.</p>
<p><img src="/img/failure_bc.png" alt="image-20200419033525905"></p>
<p>​					<em>Source : <a href="https://web.stanford.edu/class/cs234/slides/lecture7.pdf">https://web.stanford.edu/class/cs234/slides/lecture7.pdf</a></em></p>
<h3 id="dagger-dataset-aggregation-algorithm">DAgger (Dataset Aggregation) Algorithm</h3>
<p>This is basically an improved version of Behaviour cloning algorithms we discussed above.</p>
<p>Primary shortcoming of BC was that the data it had for training was static and agent could lead to unknown states where it doesn&rsquo;t have expert demonstrations.</p>
<p>We could improve that by keeping expert in loop of training and querying expert in each loop to collect more data.</p>
<pre><code class="language-mermaid">stateDiagram
    Expert_labelling_new_data --&gt; Policy_learning_from_new_data
    Policy_learning_from_new_data --&gt; Sampling_data_from_learned_policy
    Sampling_data_from_learned_policy --&gt; Expert_labelling_new_data
</code></pre>
<p>The DAgger algorithms works as follows:</p>
<ul>
<li>Initial policy: $\pi$ <sub>0</sub></li>
<li>For m = 1:
<ul>
<li>Collect trajectories $\tau$ sampled from policy $\pi$<sub>m-1</sub></li>
<li>Estimate state distribution by discarding actions from $\tau$.</li>
<li>Ask expert to label/feedback on those states interactively.</li>
<li>Creating union of data collected till now  $\tau$<sub>1,2,&hellip;m</sub></li>
<li>Training $\pi$ on this union of data</li>
</ul>
</li>
</ul>
<p>DAgger is very efficient method, which doesn&rsquo;t have shortcomings of Behaviour cloning algorithm. The only limitation of this method is the fact, that we need an expert that can evaluate the agent’s actions at all times, which is not possible in some applications.</p>
<h4 id="lets-see-implementation-of-dagger">Let&rsquo;s see implementation of DAgger</h4>
<p>I have used code from Sergey Levine&rsquo;s 
<a href="http://rail.eecs.berkeley.edu/deeprlcourse/" target="_blank" rel="noopener">CS285 Deep Reinforcement Learning course</a> material. If you want to dive deep into Deep Reinforcement learning, it&rsquo;s a gold  mine!</p>
<p>Head over to my github repository - <a href="https://github.com/Shivanshmundra/CS285-DeepRL-Solutions/tree/master/hw1">https://github.com/Shivanshmundra/CS285-DeepRL-Solutions/tree/master/hw1</a> for DAgger implementation on different gym environments.</p>
<p>In this solution, instead of human expert labelling state space, we have an expert policy which when queried, induce actions on given states. You can see with every iteration of Data Aggregation, episodic reward increases and agent approach towards convergence.</p>
<p>This repository also contain implementation of Behaviour cloning to compare between BC and DAgger algorithm.</p>
<p>Some of trained policies on different environments:</p>





  











<figure id="figure-ant-v2-environment">


  <a data-fancybox="" href="/img/ant_imi_rl.gif" data-caption="Ant-v2 Environment">


  <img src="/img/ant_imi_rl.gif" alt=""  >
</a>


  
  
  <figcaption>
    Ant-v2 Environment
  </figcaption>


</figure>






  











<figure id="figure-hopper-v2-environment">


  <a data-fancybox="" href="/img/hopper_imi_rl.gif" data-caption="Hopper-v2 Environment">


  <img src="/img/hopper_imi_rl.gif" alt=""  >
</a>


  
  
  <figcaption>
    Hopper-v2 Environment
  </figcaption>


</figure>






  











<figure id="figure-humanoid-v2-environment">


  <a data-fancybox="" href="/img/human_imi_rl.gif" data-caption="Humanoid-v2 Environment">


  <img src="/img/human_imi_rl.gif" alt=""  >
</a>


  
  
  <figcaption>
    Humanoid-v2 Environment
  </figcaption>


</figure>

<p>In all above simulations, on the left is trained policy using <strong>DAgger</strong> algorithm and on right is expert policy which was used during training.</p>
<hr>
<h3 id="other-algorithms">Other Algorithms</h3>
<p>All algorithms explained above are cateegorised as &ldquo;basic&rdquo; algorithms in Imitation learning. There are several other algorithms to discuss but I haven&rsquo;t understood them completely.</p>
<p>Some of them are:</p>
<ul>
<li>
<p><strong>Inverse Reinforcement Learning(IRL)</strong> :</p>
<ul>
<li>Learns the reward function from expert trajectories, then derives optimal policy.</li>
<li>It&rsquo;s very expensive to run.</li>
<li>Indirectly learns optimal policy from reward function.</li>
</ul>
</li>
<li>
<p><strong>Generative Adversarial Imitation Learning(GAIL)</strong> :</p>
<ul>
<li>It learns the policy, not the reward function from data.</li>
<li>Sometimes, it&rsquo;s better than &ldquo;expert&rdquo; policy.</li>
<li>Idea is inspired from Generative Adversarial Networks, where we need to approximate ground truth probability distribution.</li>
<li>Here we need to approximate &ldquo;expert&rdquo; state-action distribution.</li>
<li>The goal is to find a policy pi-theta such that the discriminator cannot distinguish between states following the pi-theta as opposed to those from pi-expert.</li>
</ul>
</li>
</ul>
<hr>
<p>So this was a detour of Imitation Learning, Hope you found it insightful! I would love to hear feedback, if any. ❤️</p>
<hr>
<h3 id="references">References</h3>
<ul>
<li><a href="https://medium.com/@SmartLabAI/a-brief-overview-of-imitation-learning-8a8a75c44a9c">https://medium.com/@SmartLabAI/a-brief-overview-of-imitation-learning-8a8a75c44a9c</a></li>
<li><a href="http://rail.eecs.berkeley.edu/deeprlcourse/">http://rail.eecs.berkeley.edu/deeprlcourse/</a></li>
<li><a href="https://github.com/Shivanshmundra/CS285-DeepRL-Solutions/tree/master/hw1">https://github.com/Shivanshmundra/CS285-DeepRL-Solutions/tree/master/hw1</a></li>
<li><a href="https://hollygrimm.com/rl_gail">https://hollygrimm.com/rl_gail</a></li>
<li><a href="https://medium.com/@sanketgujar95/generative-adversarial-imitation-learning-266f45634e60">https://medium.com/@sanketgujar95/generative-adversarial-imitation-learning-266f45634e60</a></li>
<li><a href="https://medium.com/@jonathan_hui/rl-imitation-learning-ac28116c02fc">https://medium.com/@jonathan_hui/rl-imitation-learning-ac28116c02fc</a></li>
</ul>

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/reinforcement-learning/">Reinforcement Learning</a>
  
  <a class="badge badge-light" href="/tags/imitation-learning/">Imitation Learning</a>
  
  <a class="badge badge-light" href="/tags/machine-learning/">Machine Learning</a>
  
  <a class="badge badge-light" href="/tags/gan/">GAN</a>
  
  <a class="badge badge-light" href="/tags/behaviour-cloning/">Behaviour Cloning</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://shivanshmundra.github.io/post/imitation_learning/&amp;text=Intro%20to%20Imitation%20Learning:%20From%20Why%20to%20How!" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Intro%20to%20Imitation%20Learning:%20From%20Why%20to%20How!&amp;body=https://shivanshmundra.github.io/post/imitation_learning/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://shivanshmundra.github.io/post/imitation_learning/&amp;title=Intro%20to%20Imitation%20Learning:%20From%20Why%20to%20How!" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
  </ul>
</div>












  
    
    





  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      <img class="avatar mr-3 avatar-circle" src="https://s.gravatar.com/avatar/0c94ffc55ffed4b494bfc277d688047e?s=200')" alt="Shivansh Mundra">
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://shivanshmundra.github.io/">Shivansh Mundra</a></h5>
      <h6 class="card-subtitle">Pre-Final Year Undergraduate Student</h6>
      
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/MundraShivansh" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/shivansh-mundra-300849140/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/Shivanshmundra" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="/files/cv.pdf" >
        <i class="ai ai-cv"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  





<section id="comments">
  
    
<div id="disqus_thread"></div>
<script>
  let disqus_config = function () {
    
    
    
  };
  (function() {
    if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
      document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
      return;
    }
    var d = document, s = d.createElement('script'); s.async = true;
    s.src = 'https://' + "shivanshmundra-github-io" + '.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  
</section>






  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/post/multilabel/">Multi Label Classification using Vowpal Wabbit library: From Why to How</a></li>
      
    </ul>
  </div>
  



  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.4.8/mermaid.min.js" integrity="sha256-lyWCDMnMeZiXRi7Zl54sZGKYmgQs4izcT7+tKc+KUBk=" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    <script id="dsq-count-scr" src="https://shivanshmundra-github-io.disqus.com/count.js" async></script>
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.37431be2d92d7fb0160054761ab79602.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    Shivansh Mundra &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
